{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"mopet \ud83d\udef5 The mildly ominous parameter exploration toolkit Isn't it strange that, although parameter explorations are a crucial part of computational modeling, there are almost no Python tools available for making your life easier? mopet is here to help! You can run extensive grid searches in parallel (powered by ray ) and store extremely huge amounts of data into a HDF file (powered by pytables ) for later analysis - or whatever your excuse is for buying yet another hard disk. Installation \ud83d\udcbb The easiest way to get going is to install the pypi package using pip : pip install mopet Alternatively, you can also clone this repository and install all dependencies with git clone https://github.com/caglorithm/mopet.git cd mopet/ pip install -r requirements.txt pip install . Example usage \ud83d\udc1d Feel free to have a look at the Documentation page . Setting up an exploration is as easy as can be! # first we define an toy evaluation function def distance_from_circle ( params ): # let's simply calculate the distance of # the x-y parameters to the unit circle distance = abs (( params [ \"x\" ] ** 2 + params [ \"y\" ] ** 2 ) - # we package the result into a dictionary result = { \"result\" : distance } return result Let's set up the exploration by defining the parameters to explore and passing the evaluation function from above: import numpy as np import mopet explore_params = { \"x\" : np . linspace ( - 2 , 2 , 21 ), \"y\" : np . linspace ( - 2 , 2 , 21 )} ex = mopet . Exploration ( distance_from_circle , explore_params ) Running the exploration is in parallel and is handled by ray . You can also use a private cluster or cloud infrastructure, see here for more info. ex . run () >> 100 %| \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 441 / 441 [ 426.57 it / s ] After your exploration has finished, you will find a file exploration.h5 in your current directory with all the runs, their parameters and their outputs, neatly organized. If you open this file (with HDFView for example), you'll see something like this: Loading exploration results You can load the exploration results using ex . load_results ( arrays = True ) Note that using arrays=True will load all results into memory (as opposed to just the parameters of each run). Please make sure that you have enough free memory for this since your simulation results could be huge. If you do not want this, you can load individual results using their run_id (which is an integer counting up one per run): ex . get_run ( run_id = 0 ) After using ex.load_results() , an overview of all runs and their parameters is given as a pandas DataFrame, available as ex.df . Using ex.load_results() with the default parameters will automatically aggregate all scalar results into this table, like distance in our example above, which is a float. Using some fancy pivoting, we can create a 2D matrix with the results as entries pivoted = ex . df . pivot_table ( values = 'result' , index = 'y' , columns = 'x' , aggfunc = 'first' ) Let's plot the results! import matplotlib.pyplot as plt plt . imshow ( pivoted , \\ extent = [ min ( ex . df . x ), max ( ex . df . x ), min ( ex . df . y ), max ( ex . df . y )], origin = 'lower' ) plt . colorbar ( label = 'Distance from unit circle' ) plt . xlabel ( \"x\" ) plt . ylabel ( \"y\" ) More information \ud83d\udcd3 Inspired by \ud83e\udd14 mopet is inspired by pypet , a wonderful python parameter exploration toolkit. I have been using pypet for a very long time and I'm greatful for its existence! Unfortunately, the project is not maintained anymore and has run into several compatibility issues, which was the primary reason why I built mopet . Built With \ud83d\udc9e mopet is built on other amazing open source projects: ray - A fast and simple framework for building and running distributed applications. pytables - A Python package to manage extremely large amounts of data. tqdm - A Fast, Extensible Progress Bar for Python and CLI pandas - Flexible and powerful data analysis / manipulation library for Python numpy - The fundamental package for scientific computing with Python","title":"Home"},{"location":"#mopet","text":"The mildly ominous parameter exploration toolkit Isn't it strange that, although parameter explorations are a crucial part of computational modeling, there are almost no Python tools available for making your life easier? mopet is here to help! You can run extensive grid searches in parallel (powered by ray ) and store extremely huge amounts of data into a HDF file (powered by pytables ) for later analysis - or whatever your excuse is for buying yet another hard disk.","title":"mopet \ud83d\udef5"},{"location":"#installation","text":"The easiest way to get going is to install the pypi package using pip : pip install mopet Alternatively, you can also clone this repository and install all dependencies with git clone https://github.com/caglorithm/mopet.git cd mopet/ pip install -r requirements.txt pip install .","title":"Installation \ud83d\udcbb"},{"location":"#example-usage","text":"Feel free to have a look at the Documentation page . Setting up an exploration is as easy as can be! # first we define an toy evaluation function def distance_from_circle ( params ): # let's simply calculate the distance of # the x-y parameters to the unit circle distance = abs (( params [ \"x\" ] ** 2 + params [ \"y\" ] ** 2 ) - # we package the result into a dictionary result = { \"result\" : distance } return result Let's set up the exploration by defining the parameters to explore and passing the evaluation function from above: import numpy as np import mopet explore_params = { \"x\" : np . linspace ( - 2 , 2 , 21 ), \"y\" : np . linspace ( - 2 , 2 , 21 )} ex = mopet . Exploration ( distance_from_circle , explore_params ) Running the exploration is in parallel and is handled by ray . You can also use a private cluster or cloud infrastructure, see here for more info. ex . run () >> 100 %| \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 441 / 441 [ 426.57 it / s ] After your exploration has finished, you will find a file exploration.h5 in your current directory with all the runs, their parameters and their outputs, neatly organized. If you open this file (with HDFView for example), you'll see something like this:","title":"Example usage \ud83d\udc1d"},{"location":"#loading-exploration-results","text":"You can load the exploration results using ex . load_results ( arrays = True ) Note that using arrays=True will load all results into memory (as opposed to just the parameters of each run). Please make sure that you have enough free memory for this since your simulation results could be huge. If you do not want this, you can load individual results using their run_id (which is an integer counting up one per run): ex . get_run ( run_id = 0 ) After using ex.load_results() , an overview of all runs and their parameters is given as a pandas DataFrame, available as ex.df . Using ex.load_results() with the default parameters will automatically aggregate all scalar results into this table, like distance in our example above, which is a float. Using some fancy pivoting, we can create a 2D matrix with the results as entries pivoted = ex . df . pivot_table ( values = 'result' , index = 'y' , columns = 'x' , aggfunc = 'first' ) Let's plot the results! import matplotlib.pyplot as plt plt . imshow ( pivoted , \\ extent = [ min ( ex . df . x ), max ( ex . df . x ), min ( ex . df . y ), max ( ex . df . y )], origin = 'lower' ) plt . colorbar ( label = 'Distance from unit circle' ) plt . xlabel ( \"x\" ) plt . ylabel ( \"y\" )","title":"Loading exploration results"},{"location":"#more-information","text":"","title":"More information \ud83d\udcd3"},{"location":"#inspired-by","text":"mopet is inspired by pypet , a wonderful python parameter exploration toolkit. I have been using pypet for a very long time and I'm greatful for its existence! Unfortunately, the project is not maintained anymore and has run into several compatibility issues, which was the primary reason why I built mopet .","title":"Inspired by \ud83e\udd14"},{"location":"#built-with","text":"mopet is built on other amazing open source projects: ray - A fast and simple framework for building and running distributed applications. pytables - A Python package to manage extremely large amounts of data. tqdm - A Fast, Extensible Progress Bar for Python and CLI pandas - Flexible and powerful data analysis / manipulation library for Python numpy - The fundamental package for scientific computing with Python","title":"Built With \ud83d\udc9e"},{"location":"mopet/","text":"Mopet Exploration df property readonly Returns a dataframe with exploration results. Creates it from new if it doesn't exist yet. Returns: Type Description pandas.DataFrame Dataframe with exploration results __init__ ( self , function , explore_params , default_params = None , exploration_name = None , hdf_filename = None , num_cpus = None , num_gpus = None ) special Defines a parameter exploration of a given function . Parameters: Name Type Description Default function function Function to evaluate at each run required explore_params dict Exploration parameters (individual) for each run required default_params dict Default (shared) parameters to load for each run, optional, defaults to None None exploration_name str, optional Name of the run, will create a name if left empty, defaults to None None hdf_filename str, optional Filename of the hdf storage file, defaults to None None num_cpus int Number of desired CPU cores passed to ray, defaults to None None num_gpus int Number of desired GPUs passed to ray, defaults to None None Returns: Type Description Exploration instance Source code in mopet/mopet.py def __init__ ( self , function , explore_params , default_params = None , exploration_name = None , hdf_filename = None , num_cpus : int = None , num_gpus : int = None , ): \"\"\"Defines a parameter exploration of a given `function`. :param function: Function to evaluate at each run :type function: function :param explore_params: Exploration parameters (individual) for each run :type explore_params: dict :param default_params: Default (shared) parameters to load for each run, optional, defaults to None :type default_params: dict :param exploration_name: Name of the run, will create a name if left empty, defaults to None :type exploration_name: str, optional :param hdf_filename: Filename of the hdf storage file, defaults to None :type hdf_filename: str, optional :param num_cpus: Number of desired CPU cores passed to ray, defaults to None :type num_cpus: int, optional :param num_gpus: Number of desired GPUs passed to ray, defaults to None :type num_gpus: int, optional :return: Exploration instance \"\"\" self . function = function self . results = {} self . results_params = [] if default_params is not None : self . default_params = copy . deepcopy ( default_params ) self . full_params = True else : self . default_params = None self . full_params = False self . explore_params = copy . deepcopy ( explore_params ) if exploration_name is None : exploration_name = \"exploration\" + datetime . datetime . now () . strftime ( \"_%Y_%m_ %d _%HH_%MM_%SS\" ) self . exploration_name = exploration_name if hdf_filename is None : hdf_filename = \"exploration.h5\" self . hdf_filename = hdf_filename self . dfResults = None # status self . _hdf_open_for_reading = False # List of all parameter combinations generated when exploration starts self . explore_params_list = None # Dict with runId as keys and explored parameter dict as value. # Will be filled when exploration starts. self . run_params_dict = {} # Dict with runId as keys and explored parameter dict as value. # Will be filled when calling `load_results`. self . params = {} # Ray configuration self . num_gpus = num_gpus self . num_cpus = num_cpus close_hdf ( self ) Close a previously opened HDF file. Source code in mopet/mopet.py def close_hdf ( self ): \"\"\"Close a previously opened HDF file.\"\"\" self . h5file . close () self . _hdf_open_for_reading = False logging . info ( f \" { self . hdf_filename } closed.\" ) get_run ( self , run_id = None , run_name = None , filename = None , exploration_name = None ) Get a single result from a previous exploration. This function will load a single result from the HDF file. Use this function if you want to avoid loading all results to memory, which you can do using .load_results(arrays=True) . Note: This function will open the HDF for reading but will not close it afterwards! This is to speed up many sequential loads but it also means that you have to close the HDF file yourself. You can do this by using .close_hdf() . Parameters: Name Type Description Default run_id int, optional Unique id of the run. Has to be given if run_name is not given, defaults to None None run_name str, optional The name of the run. Has to be given if run_id is not given, defaults to None None filename str, optional Filename of the HDF with previous exploration results. Previously used filename will be used if not given, defaults to None None exploration_name str, optional Name of the exploration to load data from. Previously used exploration_name will be used if not given, defaults to None None Returns: Type Description dict Results of the run Source code in mopet/mopet.py def get_run ( self , run_id = None , run_name = None , filename = None , exploration_name = None ): \"\"\"Get a single result from a previous exploration. This function will load a single result from the HDF file. Use this function if you want to avoid loading all results to memory, which you can do using `.load_results(arrays=True)`. Note: This function will open the HDF for reading but will not close it afterwards! This is to speed up many sequential loads but it also means that you have to close the HDF file yourself. You can do this by using `.close_hdf()`. :param run_id: Unique id of the run. Has to be given if run_name is not given, defaults to None :type run_id: int, optional :param run_name: The name of the run. Has to be given if run_id is not given, defaults to None :type run_name: str, optional :param filename: Filename of the HDF with previous exploration results. Previously used filename will be used if not given, defaults to None :type filename: str, optional :param exploration_name: Name of the exploration to load data from. Previously used exploration_name will be used if not given, defaults to None :type exploration_name: str, optional :return: Results of the run :rtype: dict :raises: NoSuchExplorationError if hdf5 file does not contain `exploration_name` group. \"\"\" # get result by id or if not then by run_name (hdf_run) assert run_id is not None or run_name is not None , \"Either use `run_id` or `run_name`.\" if exploration_name : self . exploration_name = exploration_name if run_id is not None : run_name = self . RUN_PREFIX + str ( run_id ) if not self . _hdf_open_for_reading : self . _open_hdf ( filename ) try : run_results_group = self . h5file . get_node ( \"/\" + self . exploration_name , \"runs\" )[ run_name ] except NoSuchNodeError : raise ExplorationNotFoundError ( \"Exploration %s could not be found in HDF file %s \" . format ( self . exploration_name , self . hdf_filename ) ) result = self . _read_group_as_dict ( run_results_group ) return result load_results ( self , filename = None , exploration_name = None , arrays = False , as_dict = False ) Load results from previous explorations. This function will open an HDF file and look for an exploration. It will create a Pandas Dataframe object (accessible through the attribute .df ) with a list of all runs and their parameters. You can load the exploration results using following parameters: If arrays==False , all scalar results from the exploration will be added to the Dataframe (default). If arrays==True , then all results, including (larger) numpy arrays will be loaded. This can take up a lot of RAM since all results will be available. Only use this option if you know that you have enough memory. Otherwise, you might want to skip this and load results separately using the method .get_run() . If as_dict==True , all results will be loaded and saved to the attribute .results regardless of their type. Will use even more memory. Parameters: Name Type Description Default filename str, optional Filename of HDF file, uses default filename or previously used filename if not given, defaults to None None exploration_name str, optional Name of the exploration, same as the group names of the explorations in the HDF file, defaults to None None arrays bool, optional Aggregate all results, including arrays into the results Dataframe, defaults to False False as_dict bool, optional Load all results into a dictionary available as the attribute .results . Can use a lot of RAM, defaults to False False Exceptions: Type Description Hdf5FileNotExistsError if file with filename does not exist. Source code in mopet/mopet.py def load_results ( self , filename = None , exploration_name = None , arrays = False , as_dict = False ): \"\"\"Load results from previous explorations. This function will open an HDF file and look for an exploration. It will create a Pandas `Dataframe` object (accessible through the attribute `.df`) with a list of all runs and their parameters. You can load the exploration results using following parameters: - If `arrays==False`, all scalar results from the exploration will be added to the Dataframe (default). - If `arrays==True`, then all results, including (larger) numpy arrays will be loaded. This can take up a lot of RAM since all results will be available. Only use this option if you know that you have enough memory. Otherwise, you might want to skip this and load results separately using the method `.get_run()`. - If `as_dict==True`, all results will be loaded and saved to the attribute `.results` regardless of their type. Will use even more memory. :param filename: Filename of HDF file, uses default filename or previously used filename if not given, defaults to None :type filename: str, optional :param exploration_name: Name of the exploration, same as the group names of the explorations in the HDF file, defaults to None :type exploration_name: str, optional :param arrays: Aggregate all results, including arrays into the results Dataframe, defaults to False :type arrays: bool, optional :param as_dict: Load all results into a dictionary available as the attribute `.results`. Can use a lot of RAM, defaults to False :type as_dict: bool, optional :raises Hdf5FileNotExistsError: if file with `filename` does not exist. \"\"\" if exploration_name is None : exploration_name = self . exploration_name else : self . exploration_name = exploration_name self . _open_hdf ( filename = filename ) self . _load_all_results ( exploration_name , as_dict = as_dict ) self . _create_df () self . _aggregate_results ( exploration_name , arrays = arrays ) self . close_hdf () run ( self ) Start parameter exploration. TODO: Pass kwargs in run() to the exploration function Exceptions: Type Description ExplorationExistsError if exploration with same name already exists in HDF5 file. Source code in mopet/mopet.py def run ( self ): \"\"\"Start parameter exploration. TODO: Pass kwargs in run() to the exploration function :raises ExplorationExistsError: if exploration with same name already exists in HDF5 file. \"\"\" # Initialize ray self . _init_ray ( num_cpus = self . num_cpus , num_gpus = self . num_gpus ) # Create a list of all combinations of parameters from explore_params self . explore_params_list = self . _cartesian_product_dict ( self . explore_params ) # Initialize hdf storage self . _pre_storage_routine () # ----------------------------- # Set up all simulations # ----------------------------- # remember the time start_time = time . time () # a unique id for each run run_id = 0 # contains ray objects of each run ray_returns = {} # contains all exploration parameters of each run self . run_params_dict = {} logging . info ( f \"Starting { len ( self . explore_params_list ) } jobs.\" ) # cycle through all parameter combinations for update_params in tqdm . tqdm ( self . explore_params_list ): if self . full_params and self . default_params is not None : # load the default parameters run_params = copy . deepcopy ( self . default_params ) # and update them with the explored parameters run_params . update ( update_params ) else : run_params = copy . deepcopy ( update_params ) # start all ray jobs and remember the ray object # pylint: disable=no-member ray_returns [ run_id ] = _ray_remote . remote ( self . function , run_params ) # store this runs explore parameters self . run_params_dict [ run_id ] = copy . deepcopy ( update_params ) # increment the run id run_id += 1 # stop measuring time end_time = time . time () - start_time logging . info ( f \"Runs took { end_time } s to submit.\" ) # ----------------------------- # Reduce and store all results # ----------------------------- # remember the time start_time = time . time () # cycle through all returned ray objects for run_id , ray_return in tqdm . tqdm ( ray_returns . items ()): # get the appropriate parameters for this run run_param = self . run_params_dict [ run_id ] # queue object for storage self . _store_result ( run_id , ray_return , run_param ) # remove LOCAL_REFERENCE in form of ObjectId from ray's object store. ray_returns [ run_id ] = None # stop measuring time end_time = time . time () - start_time logging . info ( f \"Runs and storage took { end_time } s to complete.\" ) # tear down hdf storage self . _post_storage_routine () self . _shutdown_ray ()","title":"Mopet"},{"location":"mopet/#mopet","text":"","title":"Mopet"},{"location":"mopet/#mopet.mopet","text":"","title":"mopet.mopet"},{"location":"mopet/#mopet.mopet.Exploration","text":"","title":"Exploration"},{"location":"mopet/#mopet.mopet.Exploration.df","text":"Returns a dataframe with exploration results. Creates it from new if it doesn't exist yet. Returns: Type Description pandas.DataFrame Dataframe with exploration results","title":"df"},{"location":"mopet/#mopet.mopet.Exploration.__init__","text":"Defines a parameter exploration of a given function . Parameters: Name Type Description Default function function Function to evaluate at each run required explore_params dict Exploration parameters (individual) for each run required default_params dict Default (shared) parameters to load for each run, optional, defaults to None None exploration_name str, optional Name of the run, will create a name if left empty, defaults to None None hdf_filename str, optional Filename of the hdf storage file, defaults to None None num_cpus int Number of desired CPU cores passed to ray, defaults to None None num_gpus int Number of desired GPUs passed to ray, defaults to None None Returns: Type Description Exploration instance Source code in mopet/mopet.py def __init__ ( self , function , explore_params , default_params = None , exploration_name = None , hdf_filename = None , num_cpus : int = None , num_gpus : int = None , ): \"\"\"Defines a parameter exploration of a given `function`. :param function: Function to evaluate at each run :type function: function :param explore_params: Exploration parameters (individual) for each run :type explore_params: dict :param default_params: Default (shared) parameters to load for each run, optional, defaults to None :type default_params: dict :param exploration_name: Name of the run, will create a name if left empty, defaults to None :type exploration_name: str, optional :param hdf_filename: Filename of the hdf storage file, defaults to None :type hdf_filename: str, optional :param num_cpus: Number of desired CPU cores passed to ray, defaults to None :type num_cpus: int, optional :param num_gpus: Number of desired GPUs passed to ray, defaults to None :type num_gpus: int, optional :return: Exploration instance \"\"\" self . function = function self . results = {} self . results_params = [] if default_params is not None : self . default_params = copy . deepcopy ( default_params ) self . full_params = True else : self . default_params = None self . full_params = False self . explore_params = copy . deepcopy ( explore_params ) if exploration_name is None : exploration_name = \"exploration\" + datetime . datetime . now () . strftime ( \"_%Y_%m_ %d _%HH_%MM_%SS\" ) self . exploration_name = exploration_name if hdf_filename is None : hdf_filename = \"exploration.h5\" self . hdf_filename = hdf_filename self . dfResults = None # status self . _hdf_open_for_reading = False # List of all parameter combinations generated when exploration starts self . explore_params_list = None # Dict with runId as keys and explored parameter dict as value. # Will be filled when exploration starts. self . run_params_dict = {} # Dict with runId as keys and explored parameter dict as value. # Will be filled when calling `load_results`. self . params = {} # Ray configuration self . num_gpus = num_gpus self . num_cpus = num_cpus","title":"__init__()"},{"location":"mopet/#mopet.mopet.Exploration.close_hdf","text":"Close a previously opened HDF file. Source code in mopet/mopet.py def close_hdf ( self ): \"\"\"Close a previously opened HDF file.\"\"\" self . h5file . close () self . _hdf_open_for_reading = False logging . info ( f \" { self . hdf_filename } closed.\" )","title":"close_hdf()"},{"location":"mopet/#mopet.mopet.Exploration.get_run","text":"Get a single result from a previous exploration. This function will load a single result from the HDF file. Use this function if you want to avoid loading all results to memory, which you can do using .load_results(arrays=True) . Note: This function will open the HDF for reading but will not close it afterwards! This is to speed up many sequential loads but it also means that you have to close the HDF file yourself. You can do this by using .close_hdf() . Parameters: Name Type Description Default run_id int, optional Unique id of the run. Has to be given if run_name is not given, defaults to None None run_name str, optional The name of the run. Has to be given if run_id is not given, defaults to None None filename str, optional Filename of the HDF with previous exploration results. Previously used filename will be used if not given, defaults to None None exploration_name str, optional Name of the exploration to load data from. Previously used exploration_name will be used if not given, defaults to None None Returns: Type Description dict Results of the run Source code in mopet/mopet.py def get_run ( self , run_id = None , run_name = None , filename = None , exploration_name = None ): \"\"\"Get a single result from a previous exploration. This function will load a single result from the HDF file. Use this function if you want to avoid loading all results to memory, which you can do using `.load_results(arrays=True)`. Note: This function will open the HDF for reading but will not close it afterwards! This is to speed up many sequential loads but it also means that you have to close the HDF file yourself. You can do this by using `.close_hdf()`. :param run_id: Unique id of the run. Has to be given if run_name is not given, defaults to None :type run_id: int, optional :param run_name: The name of the run. Has to be given if run_id is not given, defaults to None :type run_name: str, optional :param filename: Filename of the HDF with previous exploration results. Previously used filename will be used if not given, defaults to None :type filename: str, optional :param exploration_name: Name of the exploration to load data from. Previously used exploration_name will be used if not given, defaults to None :type exploration_name: str, optional :return: Results of the run :rtype: dict :raises: NoSuchExplorationError if hdf5 file does not contain `exploration_name` group. \"\"\" # get result by id or if not then by run_name (hdf_run) assert run_id is not None or run_name is not None , \"Either use `run_id` or `run_name`.\" if exploration_name : self . exploration_name = exploration_name if run_id is not None : run_name = self . RUN_PREFIX + str ( run_id ) if not self . _hdf_open_for_reading : self . _open_hdf ( filename ) try : run_results_group = self . h5file . get_node ( \"/\" + self . exploration_name , \"runs\" )[ run_name ] except NoSuchNodeError : raise ExplorationNotFoundError ( \"Exploration %s could not be found in HDF file %s \" . format ( self . exploration_name , self . hdf_filename ) ) result = self . _read_group_as_dict ( run_results_group ) return result","title":"get_run()"},{"location":"mopet/#mopet.mopet.Exploration.load_results","text":"Load results from previous explorations. This function will open an HDF file and look for an exploration. It will create a Pandas Dataframe object (accessible through the attribute .df ) with a list of all runs and their parameters. You can load the exploration results using following parameters: If arrays==False , all scalar results from the exploration will be added to the Dataframe (default). If arrays==True , then all results, including (larger) numpy arrays will be loaded. This can take up a lot of RAM since all results will be available. Only use this option if you know that you have enough memory. Otherwise, you might want to skip this and load results separately using the method .get_run() . If as_dict==True , all results will be loaded and saved to the attribute .results regardless of their type. Will use even more memory. Parameters: Name Type Description Default filename str, optional Filename of HDF file, uses default filename or previously used filename if not given, defaults to None None exploration_name str, optional Name of the exploration, same as the group names of the explorations in the HDF file, defaults to None None arrays bool, optional Aggregate all results, including arrays into the results Dataframe, defaults to False False as_dict bool, optional Load all results into a dictionary available as the attribute .results . Can use a lot of RAM, defaults to False False Exceptions: Type Description Hdf5FileNotExistsError if file with filename does not exist. Source code in mopet/mopet.py def load_results ( self , filename = None , exploration_name = None , arrays = False , as_dict = False ): \"\"\"Load results from previous explorations. This function will open an HDF file and look for an exploration. It will create a Pandas `Dataframe` object (accessible through the attribute `.df`) with a list of all runs and their parameters. You can load the exploration results using following parameters: - If `arrays==False`, all scalar results from the exploration will be added to the Dataframe (default). - If `arrays==True`, then all results, including (larger) numpy arrays will be loaded. This can take up a lot of RAM since all results will be available. Only use this option if you know that you have enough memory. Otherwise, you might want to skip this and load results separately using the method `.get_run()`. - If `as_dict==True`, all results will be loaded and saved to the attribute `.results` regardless of their type. Will use even more memory. :param filename: Filename of HDF file, uses default filename or previously used filename if not given, defaults to None :type filename: str, optional :param exploration_name: Name of the exploration, same as the group names of the explorations in the HDF file, defaults to None :type exploration_name: str, optional :param arrays: Aggregate all results, including arrays into the results Dataframe, defaults to False :type arrays: bool, optional :param as_dict: Load all results into a dictionary available as the attribute `.results`. Can use a lot of RAM, defaults to False :type as_dict: bool, optional :raises Hdf5FileNotExistsError: if file with `filename` does not exist. \"\"\" if exploration_name is None : exploration_name = self . exploration_name else : self . exploration_name = exploration_name self . _open_hdf ( filename = filename ) self . _load_all_results ( exploration_name , as_dict = as_dict ) self . _create_df () self . _aggregate_results ( exploration_name , arrays = arrays ) self . close_hdf ()","title":"load_results()"},{"location":"mopet/#mopet.mopet.Exploration.run","text":"Start parameter exploration. TODO: Pass kwargs in run() to the exploration function Exceptions: Type Description ExplorationExistsError if exploration with same name already exists in HDF5 file. Source code in mopet/mopet.py def run ( self ): \"\"\"Start parameter exploration. TODO: Pass kwargs in run() to the exploration function :raises ExplorationExistsError: if exploration with same name already exists in HDF5 file. \"\"\" # Initialize ray self . _init_ray ( num_cpus = self . num_cpus , num_gpus = self . num_gpus ) # Create a list of all combinations of parameters from explore_params self . explore_params_list = self . _cartesian_product_dict ( self . explore_params ) # Initialize hdf storage self . _pre_storage_routine () # ----------------------------- # Set up all simulations # ----------------------------- # remember the time start_time = time . time () # a unique id for each run run_id = 0 # contains ray objects of each run ray_returns = {} # contains all exploration parameters of each run self . run_params_dict = {} logging . info ( f \"Starting { len ( self . explore_params_list ) } jobs.\" ) # cycle through all parameter combinations for update_params in tqdm . tqdm ( self . explore_params_list ): if self . full_params and self . default_params is not None : # load the default parameters run_params = copy . deepcopy ( self . default_params ) # and update them with the explored parameters run_params . update ( update_params ) else : run_params = copy . deepcopy ( update_params ) # start all ray jobs and remember the ray object # pylint: disable=no-member ray_returns [ run_id ] = _ray_remote . remote ( self . function , run_params ) # store this runs explore parameters self . run_params_dict [ run_id ] = copy . deepcopy ( update_params ) # increment the run id run_id += 1 # stop measuring time end_time = time . time () - start_time logging . info ( f \"Runs took { end_time } s to submit.\" ) # ----------------------------- # Reduce and store all results # ----------------------------- # remember the time start_time = time . time () # cycle through all returned ray objects for run_id , ray_return in tqdm . tqdm ( ray_returns . items ()): # get the appropriate parameters for this run run_param = self . run_params_dict [ run_id ] # queue object for storage self . _store_result ( run_id , ray_return , run_param ) # remove LOCAL_REFERENCE in form of ObjectId from ray's object store. ray_returns [ run_id ] = None # stop measuring time end_time = time . time () - start_time logging . info ( f \"Runs and storage took { end_time } s to complete.\" ) # tear down hdf storage self . _post_storage_routine () self . _shutdown_ray ()","title":"run()"},{"location":"examples/minimal_example/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); A very basic exploration In this example, we will perform a basic exploration with mopet . To demonstrate the usage, we will simply scan a 2D surface and, at each point, return a number that is equal to the distance to a unit circle. Of course, this is not a realistic experiment for parameter exploration but it serves as a simplified example. # change into the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) % load_ext autoreload % autoreload 2 import logging logger = logging . getLogger () logger . setLevel ( logging . INFO ) import numpy as np ! pip install matplotlib import matplotlib.pyplot as plt import mopet # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' def evalFunction ( params ): result_float = abs (( params [ \"x\" ] ** 2 + params [ \"y\" ] ** 2 ) - 1 ) result_array = np . random . randn ( np . random . randint ( 1 , 131 ), np . random . randint ( 1 , 5000 )) result = {} result [ \"float_result\" ] = result_float result [ \"array_result\" ] = result_array return result explore_params = { \"x\" : np . linspace ( - 2 , 2 , 21 ), \"y\" : np . linspace ( - 2 , 2 , 21 )} # we need this random filename to avoid testing clashes hdf_filename = f \"exploration- { np . random . randint ( 99999 ) } .h5\" ex = mopet . Exploration ( evalFunction , explore_params , hdf_filename = hdf_filename ) ex . run () 2021-02-15 13:58:23,782 INFO resource_spec.py:212 -- Starting Ray with 3.91 GiB memory available for workers and up to 1.96 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>). 2021-02-15 13:58:24,138 INFO services.py:1093 -- View the Ray dashboard at localhost:8265 INFO:root:Starting 441 jobs. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 441/441 [00:00<00:00, 457.14it/s] INFO:root:Runs took 0.9735679626464844 s to submit. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 441/441 [00:03<00:00, 118.17it/s] INFO:root:Runs and storage took 3.7421679496765137 s to complete. ex . load_results ( arrays = True ) INFO:root:exploration-55740.h5 opened for reading. INFO:root:Gettings runs of exploration ``exploration_2021_02_15_13H_58M_23S`` 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 441/441 [00:00<00:00, 903.61it/s] INFO:root:Creating new results DataFrame INFO:root:Aggregating all results ... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 441/441 [00:01<00:00, 413.07it/s] INFO:root:exploration-55740.h5 closed. len ( ex . results ) 441 ex . get_run ( 0 ) INFO:root:exploration.h5 opened for reading. {'array_result': array([[ 5.97391695e-01, -1.85095801e+00, 6.36841315e-01, ..., -3.62676558e-01, -2.09826990e-01, 1.40291897e+00], [ 1.75607948e+00, 1.05066847e+00, 8.95172810e-01, ..., -7.77506344e-01, -9.06090056e-01, 9.48383121e-04], [-2.20332623e-01, 6.78649005e-01, -8.93520258e-01, ..., -2.22872632e+00, -1.19226748e+00, -1.38276576e-01], ..., [ 7.76605125e-01, -5.22077056e-01, 4.18754799e-01, ..., 1.15120920e+00, -3.58705657e-01, -9.63737910e-01], [ 2.55826835e+00, -5.37584683e-01, 6.39454329e-01, ..., -1.99267714e-01, 5.92317635e-01, -7.96497612e-01], [ 3.18325277e-01, 2.13536242e+00, 1.12065066e+00, ..., -4.70540293e-01, 1.08954728e+00, 4.97407056e-01]]), 'float_result': 7.0} for r in ex . df . index : ex . df . loc [ r , \"mean_array_result\" ] = np . mean ( ex . get_run ( r )[ 'array_result' ]) ex . df . dropna ( axis = 'columns' , how = 'all' ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y float_result mean_array_result 0 -2 -2 7.00 0.006656 1 -2 -1.8 6.24 0.000567 10 -2 0 3.00 0.002344 100 -1.2 1.2 1.88 -0.000210 101 -1.2 1.4 2.40 0.003098 ... ... ... ... ... 95 -1.2 0.2 0.48 0.003001 96 -1.2 0.4 0.60 -0.000337 97 -1.2 0.6 0.80 0.001959 98 -1.2 0.8 1.08 -0.010278 99 -1.2 1 1.44 0.002511 441 rows \u00d7 4 columns pivoted = ex . df . pivot_table ( values = 'float_result' , index = 'y' , columns = 'x' , aggfunc = 'first' ) plt . imshow ( pivoted , \\ extent = [ min ( ex . df . x ), max ( ex . df . x ), min ( ex . df . y ), max ( ex . df . y )], origin = 'lower' ) plt . colorbar ( label = 'Distance from unit circle' ) plt . xlabel ( \"x\" ) plt . ylabel ( \"y\" ) Text(0, 0.5, 'y')","title":"Minimal example"},{"location":"examples/minimal_example/#a-very-basic-exploration","text":"In this example, we will perform a basic exploration with mopet . To demonstrate the usage, we will simply scan a 2D surface and, at each point, return a number that is equal to the distance to a unit circle. Of course, this is not a realistic experiment for parameter exploration but it serves as a simplified example. # change into the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) % load_ext autoreload % autoreload 2 import logging logger = logging . getLogger () logger . setLevel ( logging . INFO ) import numpy as np ! pip install matplotlib import matplotlib.pyplot as plt import mopet # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' def evalFunction ( params ): result_float = abs (( params [ \"x\" ] ** 2 + params [ \"y\" ] ** 2 ) - 1 ) result_array = np . random . randn ( np . random . randint ( 1 , 131 ), np . random . randint ( 1 , 5000 )) result = {} result [ \"float_result\" ] = result_float result [ \"array_result\" ] = result_array return result explore_params = { \"x\" : np . linspace ( - 2 , 2 , 21 ), \"y\" : np . linspace ( - 2 , 2 , 21 )} # we need this random filename to avoid testing clashes hdf_filename = f \"exploration- { np . random . randint ( 99999 ) } .h5\" ex = mopet . Exploration ( evalFunction , explore_params , hdf_filename = hdf_filename ) ex . run () 2021-02-15 13:58:23,782 INFO resource_spec.py:212 -- Starting Ray with 3.91 GiB memory available for workers and up to 1.96 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>). 2021-02-15 13:58:24,138 INFO services.py:1093 -- View the Ray dashboard at localhost:8265 INFO:root:Starting 441 jobs. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 441/441 [00:00<00:00, 457.14it/s] INFO:root:Runs took 0.9735679626464844 s to submit. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 441/441 [00:03<00:00, 118.17it/s] INFO:root:Runs and storage took 3.7421679496765137 s to complete. ex . load_results ( arrays = True ) INFO:root:exploration-55740.h5 opened for reading. INFO:root:Gettings runs of exploration ``exploration_2021_02_15_13H_58M_23S`` 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 441/441 [00:00<00:00, 903.61it/s] INFO:root:Creating new results DataFrame INFO:root:Aggregating all results ... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 441/441 [00:01<00:00, 413.07it/s] INFO:root:exploration-55740.h5 closed. len ( ex . results ) 441 ex . get_run ( 0 ) INFO:root:exploration.h5 opened for reading. {'array_result': array([[ 5.97391695e-01, -1.85095801e+00, 6.36841315e-01, ..., -3.62676558e-01, -2.09826990e-01, 1.40291897e+00], [ 1.75607948e+00, 1.05066847e+00, 8.95172810e-01, ..., -7.77506344e-01, -9.06090056e-01, 9.48383121e-04], [-2.20332623e-01, 6.78649005e-01, -8.93520258e-01, ..., -2.22872632e+00, -1.19226748e+00, -1.38276576e-01], ..., [ 7.76605125e-01, -5.22077056e-01, 4.18754799e-01, ..., 1.15120920e+00, -3.58705657e-01, -9.63737910e-01], [ 2.55826835e+00, -5.37584683e-01, 6.39454329e-01, ..., -1.99267714e-01, 5.92317635e-01, -7.96497612e-01], [ 3.18325277e-01, 2.13536242e+00, 1.12065066e+00, ..., -4.70540293e-01, 1.08954728e+00, 4.97407056e-01]]), 'float_result': 7.0} for r in ex . df . index : ex . df . loc [ r , \"mean_array_result\" ] = np . mean ( ex . get_run ( r )[ 'array_result' ]) ex . df . dropna ( axis = 'columns' , how = 'all' ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y float_result mean_array_result 0 -2 -2 7.00 0.006656 1 -2 -1.8 6.24 0.000567 10 -2 0 3.00 0.002344 100 -1.2 1.2 1.88 -0.000210 101 -1.2 1.4 2.40 0.003098 ... ... ... ... ... 95 -1.2 0.2 0.48 0.003001 96 -1.2 0.4 0.60 -0.000337 97 -1.2 0.6 0.80 0.001959 98 -1.2 0.8 1.08 -0.010278 99 -1.2 1 1.44 0.002511 441 rows \u00d7 4 columns pivoted = ex . df . pivot_table ( values = 'float_result' , index = 'y' , columns = 'x' , aggfunc = 'first' ) plt . imshow ( pivoted , \\ extent = [ min ( ex . df . x ), max ( ex . df . x ), min ( ex . df . y ), max ( ex . df . y )], origin = 'lower' ) plt . colorbar ( label = 'Distance from unit circle' ) plt . xlabel ( \"x\" ) plt . ylabel ( \"y\" ) Text(0, 0.5, 'y')","title":"A very basic exploration"},{"location":"examples/neurolib_brain_network/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Brain network exploration with neurolib In this example, we will run a parameter exploration of a whole-brain model that we load using the brain simulation framework neurolib . Please visit the Github repo to learn more about this library or read the gentle introduction to neurolib to learn more about the neuroscience background of neural mass models and whole-brain simulations. # change into the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) % load_ext autoreload % autoreload 2 import logging logger = logging . getLogger () logger . setLevel ( logging . INFO ) ! pip install matplotlib import matplotlib.pyplot as plt import numpy as np # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' ! pip install neurolib from neurolib.models.aln import ALNModel from neurolib.utils.loadData import Dataset import neurolib.utils.functions as func ds = Dataset ( \"hcp\" ) import mopet We load a model with parameters that generate interesting dynamics. model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) model . params [ 'duration' ] = 0.2 * 60 * 1000 model . params [ 'mue_ext_mean' ] = 1.57 model . params [ 'mui_ext_mean' ] = 1.6 # We set an appropriate level of noise model . params [ 'sigma_ou' ] = 0.09 # And turn on adaptation with a low value of spike-triggered adaptation currents. model . params [ 'b' ] = 5.0 INFO:root:aln: Model initialized. Let's run it to see what kind of output it produces! model . run ( bold = True , chunkwise = True ) plt . plot ( model . output . T ); We simualted the model with BOLD output, so let's compute the functional connectivity (fc) matrix: plt . imshow ( func . fc ( model . BOLD . BOLD [:, model . BOLD . t_BOLD > 5000 ])) <matplotlib.image.AxesImage at 0x7fc33ea35f60> This is our multi-stage evaluation function. def evaluateSimulation ( params ): model . params . update ( params ) defaultDuration = model . params [ 'duration' ] invalid_result = { \"fc\" : [ 0 ] * len ( ds . BOLDs )} logging . info ( \"Running stage 1\" ) # -------- stage wise simulation -------- # Stage 1 : simulate for a few seconds to see if there is any activity # --------------------------------------- model . params [ 'duration' ] = 3 * 1000. model . run () # check if stage 1 was successful amplitude = np . max ( model . output [:, model . t > 500 ]) - np . min ( model . output [:, model . t > 500 ]) if amplitude < 0.05 : invalid_result = { \"fc\" : 0 } return invalid_result logging . info ( \"Running stage 2\" ) # Stage 2: simulate BOLD for a few seconds to see if it moves # --------------------------------------- model . params [ 'duration' ] = 20 * 1000. model . run ( bold = True , chunkwise = True ) if np . std ( model . BOLD . BOLD [:, 5 : 10 ]) < 0.0001 : invalid_result = { \"fc\" : - 1 } return invalid_result logging . info ( \"Running stage 3\" ) # Stage 3: full and final simulation # --------------------------------------- model . params [ 'duration' ] = defaultDuration model . run ( bold = True , chunkwise = True ) # -------- evaluation here -------- scores = [] for i , fc in enumerate ( ds . FCs ): #range(len(ds.FCs)): fc_score = func . matrix_correlation ( func . fc ( model . BOLD . BOLD [:, 5 :]), fc ) scores . append ( fc_score ) meanScore = np . mean ( scores ) result_dict = { \"fc\" : meanScore } return result_dict We test run the evaluation function. model . params [ 'duration' ] = 20 * 1000. evaluateSimulation ( model . params ) INFO:root:Running stage 1 INFO:root:Running stage 2 INFO:root:Running stage 3 {'fc': 0.4537372441284651} # NOTE: These values are low for testing model . params [ 'duration' ] = 20 * 1000. explore_params = { \"a\" : np . linspace ( 0 , 40.0 , 1 ) , \"K_gl\" : np . linspace ( 100 , 400 , 1 ) , \"sigma_ou\" : np . linspace ( 0.1 , 0.5 , 1 ) } # we need this random filename to avoid testing clashes hdf_filename = f \"exploration- { np . random . randint ( 99999 ) } .h5\" ex = mopet . Exploration ( evaluateSimulation , explore_params , default_params = model . params , hdf_filename = hdf_filename ) ex . run () 2021-02-15 14:15:51,285 INFO resource_spec.py:212 -- Starting Ray with 3.03 GiB memory available for workers and up to 1.52 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>). 2021-02-15 14:15:52,039 INFO services.py:1093 -- View the Ray dashboard at localhost:8266 WARNING:root:Could not store dict entry model (type: <class 'str'>) WARNING:root:Could not store dict entry name (type: <class 'str'>) WARNING:root:Could not store dict entry description (type: <class 'str'>) WARNING:root:Could not store dict entry seed (type: <class 'NoneType'>) INFO:root:Starting 8 jobs. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:07<00:00, 1.08it/s] INFO:root:Runs took 7.463719129562378 s to submit. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:35<00:00, 4.45s/it] INFO:root:Runs and storage took 35.602142095565796 s to complete. ex . load_results ( as_dict = True ) INFO:root:exploration-48119.h5 opened for reading. INFO:root:Gettings runs of exploration ``exploration_2021_02_15_14H_15M_51S`` 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:00<00:00, 231.71it/s] INFO:root:Creating new results DataFrame INFO:root:Aggregating all results ... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:00<00:00, 834.38it/s] INFO:root:exploration-48119.h5 closed. ex . results {0: {'fc': 0.4216617659384549}, 1: {'fc': 0.19060260889456235}, 2: {'fc': 0.45774482194101823}, 3: {'fc': 0.20248027699336246}, 4: {'fc': 0}, 5: {'fc': 0.5166340757259852}, 6: {'fc': 0}, 7: {'fc': 0.5083694259142941}} ex . params {0: {'K_gl': 100.0, 'a': 0.0, 'sigma_ou': 0.1}, 1: {'K_gl': 100.0, 'a': 0.0, 'sigma_ou': 0.5}, 2: {'K_gl': 400.0, 'a': 0.0, 'sigma_ou': 0.1}, 3: {'K_gl': 400.0, 'a': 0.0, 'sigma_ou': 0.5}, 4: {'K_gl': 100.0, 'a': 40.0, 'sigma_ou': 0.1}, 5: {'K_gl': 100.0, 'a': 40.0, 'sigma_ou': 0.5}, 6: {'K_gl': 400.0, 'a': 40.0, 'sigma_ou': 0.1}, 7: {'K_gl': 400.0, 'a': 40.0, 'sigma_ou': 0.5}} ex . df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } K_gl a sigma_ou fc 0 100 0 0.1 0.421662 1 100 0 0.5 0.190603 2 400 0 0.1 0.457745 3 400 0 0.5 0.202480 4 100 40 0.1 0.000000 5 100 40 0.5 0.516634 6 400 40 0.1 0.000000 7 400 40 0.5 0.508369 sigma_selectors = np . unique ( ex . df . sigma_ou ) for s in sigma_selectors : df = ex . df [( ex . df . sigma_ou == s )] pivotdf = df . pivot_table ( values = 'fc' , index = 'K_gl' , columns = 'a' ) plt . imshow ( pivotdf , \\ extent = [ min ( df . a ), max ( df . a ), min ( df . K_gl ), max ( df . K_gl )], origin = 'lower' , aspect = 'auto' ) plt . colorbar ( label = 'Mean correlation to empirical rs-FC' ) plt . xlabel ( \"a\" ) plt . ylabel ( \"K_gl\" ) plt . title ( \"$\\sigma_ {ou} $\" + \"= {} \" . format ( s )) plt . show ()","title":"Neurolib brain network"},{"location":"examples/neurolib_brain_network/#brain-network-exploration-with-neurolib","text":"In this example, we will run a parameter exploration of a whole-brain model that we load using the brain simulation framework neurolib . Please visit the Github repo to learn more about this library or read the gentle introduction to neurolib to learn more about the neuroscience background of neural mass models and whole-brain simulations. # change into the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) % load_ext autoreload % autoreload 2 import logging logger = logging . getLogger () logger . setLevel ( logging . INFO ) ! pip install matplotlib import matplotlib.pyplot as plt import numpy as np # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' ! pip install neurolib from neurolib.models.aln import ALNModel from neurolib.utils.loadData import Dataset import neurolib.utils.functions as func ds = Dataset ( \"hcp\" ) import mopet We load a model with parameters that generate interesting dynamics. model = ALNModel ( Cmat = ds . Cmat , Dmat = ds . Dmat ) model . params [ 'duration' ] = 0.2 * 60 * 1000 model . params [ 'mue_ext_mean' ] = 1.57 model . params [ 'mui_ext_mean' ] = 1.6 # We set an appropriate level of noise model . params [ 'sigma_ou' ] = 0.09 # And turn on adaptation with a low value of spike-triggered adaptation currents. model . params [ 'b' ] = 5.0 INFO:root:aln: Model initialized. Let's run it to see what kind of output it produces! model . run ( bold = True , chunkwise = True ) plt . plot ( model . output . T ); We simualted the model with BOLD output, so let's compute the functional connectivity (fc) matrix: plt . imshow ( func . fc ( model . BOLD . BOLD [:, model . BOLD . t_BOLD > 5000 ])) <matplotlib.image.AxesImage at 0x7fc33ea35f60> This is our multi-stage evaluation function. def evaluateSimulation ( params ): model . params . update ( params ) defaultDuration = model . params [ 'duration' ] invalid_result = { \"fc\" : [ 0 ] * len ( ds . BOLDs )} logging . info ( \"Running stage 1\" ) # -------- stage wise simulation -------- # Stage 1 : simulate for a few seconds to see if there is any activity # --------------------------------------- model . params [ 'duration' ] = 3 * 1000. model . run () # check if stage 1 was successful amplitude = np . max ( model . output [:, model . t > 500 ]) - np . min ( model . output [:, model . t > 500 ]) if amplitude < 0.05 : invalid_result = { \"fc\" : 0 } return invalid_result logging . info ( \"Running stage 2\" ) # Stage 2: simulate BOLD for a few seconds to see if it moves # --------------------------------------- model . params [ 'duration' ] = 20 * 1000. model . run ( bold = True , chunkwise = True ) if np . std ( model . BOLD . BOLD [:, 5 : 10 ]) < 0.0001 : invalid_result = { \"fc\" : - 1 } return invalid_result logging . info ( \"Running stage 3\" ) # Stage 3: full and final simulation # --------------------------------------- model . params [ 'duration' ] = defaultDuration model . run ( bold = True , chunkwise = True ) # -------- evaluation here -------- scores = [] for i , fc in enumerate ( ds . FCs ): #range(len(ds.FCs)): fc_score = func . matrix_correlation ( func . fc ( model . BOLD . BOLD [:, 5 :]), fc ) scores . append ( fc_score ) meanScore = np . mean ( scores ) result_dict = { \"fc\" : meanScore } return result_dict We test run the evaluation function. model . params [ 'duration' ] = 20 * 1000. evaluateSimulation ( model . params ) INFO:root:Running stage 1 INFO:root:Running stage 2 INFO:root:Running stage 3 {'fc': 0.4537372441284651} # NOTE: These values are low for testing model . params [ 'duration' ] = 20 * 1000. explore_params = { \"a\" : np . linspace ( 0 , 40.0 , 1 ) , \"K_gl\" : np . linspace ( 100 , 400 , 1 ) , \"sigma_ou\" : np . linspace ( 0.1 , 0.5 , 1 ) } # we need this random filename to avoid testing clashes hdf_filename = f \"exploration- { np . random . randint ( 99999 ) } .h5\" ex = mopet . Exploration ( evaluateSimulation , explore_params , default_params = model . params , hdf_filename = hdf_filename ) ex . run () 2021-02-15 14:15:51,285 INFO resource_spec.py:212 -- Starting Ray with 3.03 GiB memory available for workers and up to 1.52 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>). 2021-02-15 14:15:52,039 INFO services.py:1093 -- View the Ray dashboard at localhost:8266 WARNING:root:Could not store dict entry model (type: <class 'str'>) WARNING:root:Could not store dict entry name (type: <class 'str'>) WARNING:root:Could not store dict entry description (type: <class 'str'>) WARNING:root:Could not store dict entry seed (type: <class 'NoneType'>) INFO:root:Starting 8 jobs. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:07<00:00, 1.08it/s] INFO:root:Runs took 7.463719129562378 s to submit. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:35<00:00, 4.45s/it] INFO:root:Runs and storage took 35.602142095565796 s to complete. ex . load_results ( as_dict = True ) INFO:root:exploration-48119.h5 opened for reading. INFO:root:Gettings runs of exploration ``exploration_2021_02_15_14H_15M_51S`` 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:00<00:00, 231.71it/s] INFO:root:Creating new results DataFrame INFO:root:Aggregating all results ... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:00<00:00, 834.38it/s] INFO:root:exploration-48119.h5 closed. ex . results {0: {'fc': 0.4216617659384549}, 1: {'fc': 0.19060260889456235}, 2: {'fc': 0.45774482194101823}, 3: {'fc': 0.20248027699336246}, 4: {'fc': 0}, 5: {'fc': 0.5166340757259852}, 6: {'fc': 0}, 7: {'fc': 0.5083694259142941}} ex . params {0: {'K_gl': 100.0, 'a': 0.0, 'sigma_ou': 0.1}, 1: {'K_gl': 100.0, 'a': 0.0, 'sigma_ou': 0.5}, 2: {'K_gl': 400.0, 'a': 0.0, 'sigma_ou': 0.1}, 3: {'K_gl': 400.0, 'a': 0.0, 'sigma_ou': 0.5}, 4: {'K_gl': 100.0, 'a': 40.0, 'sigma_ou': 0.1}, 5: {'K_gl': 100.0, 'a': 40.0, 'sigma_ou': 0.5}, 6: {'K_gl': 400.0, 'a': 40.0, 'sigma_ou': 0.1}, 7: {'K_gl': 400.0, 'a': 40.0, 'sigma_ou': 0.5}} ex . df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } K_gl a sigma_ou fc 0 100 0 0.1 0.421662 1 100 0 0.5 0.190603 2 400 0 0.1 0.457745 3 400 0 0.5 0.202480 4 100 40 0.1 0.000000 5 100 40 0.5 0.516634 6 400 40 0.1 0.000000 7 400 40 0.5 0.508369 sigma_selectors = np . unique ( ex . df . sigma_ou ) for s in sigma_selectors : df = ex . df [( ex . df . sigma_ou == s )] pivotdf = df . pivot_table ( values = 'fc' , index = 'K_gl' , columns = 'a' ) plt . imshow ( pivotdf , \\ extent = [ min ( df . a ), max ( df . a ), min ( df . K_gl ), max ( df . K_gl )], origin = 'lower' , aspect = 'auto' ) plt . colorbar ( label = 'Mean correlation to empirical rs-FC' ) plt . xlabel ( \"a\" ) plt . ylabel ( \"K_gl\" ) plt . title ( \"$\\sigma_ {ou} $\" + \"= {} \" . format ( s )) plt . show ()","title":"Brain network exploration with neurolib"},{"location":"examples/neurolib_example/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Parameter exploration with neurolib In this example, we will draw a bifurcation diagram of a neural mass model that we load using the brain simulation framework neurolib . Please visit the Github repo to learn more about this library or read the gentle introduction to neurolib to learn more about the neuroscience background of neural mass models and whole-brain simulations. What we will do We will scan through a 2-dimensional parameter space and record all outputs of the model to a hdf file. We will then load the simulated results from the hdf file and condense the output to a single scalar so we can plot it. Let's get to it! We'll first start with some unnecessary but useful imports for logging and auto-reloading code. You can skip this block if you don't know what it does. # change into the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) % load_ext autoreload % autoreload 2 import logging logger = logging . getLogger () logger . setLevel ( logging . INFO ) We have to install matplotlib and neurolib for this example, which we can do using the shell command syntax of jupyter using !pip install matplotlib . # install matplotlib ! pip install matplotlib import matplotlib.pyplot as plt import numpy as np # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' # install neurolib ! pip install neurolib from neurolib.models.aln import ALNModel import mopet We can now load the ALNModel model from neurolib . model = ALNModel () model . params . duration = 1 * 1000 INFO:root:aln: Model initialized. Like in other examples, we need to define an evalFunction that mopet can call. The parameters params that are passed to that function are the parameters of the model to run. We load the parameters to the model using a simple dictionary update old_dict.update(new_dict) . We then return the output of the model. def evalFunction ( params ): model . params . update ( params ) model . run () return model . outputs Now we define the parameter ranges to explore (the parameters here are called mue_ext_mean and mui_ext_mean which represent the background input to two neural populations). # NOTE: These values are low for testing! explore_params = { \"mue_ext_mean\" : np . linspace ( 0 , 3 , 3 ), \"mui_ext_mean\" : np . linspace ( 0 , 3 , 3 )} # For a real run, use these values: # explore_params = {\"mue_ext_mean\" : np.linspace(0, 3, 31), # \"mui_ext_mean\" : np.linspace(0, 3, 31)} # we need this random filename to avoid testing clashes hdf_filename = f \"exploration- { np . random . randint ( 99999 ) } .h5\" ex = mopet . Exploration ( evalFunction , explore_params , default_params = model . params , hdf_filename = hdf_filename ) Everything is ready and we can now simply run the exploration. ex . run () 2021-02-15 14:01:44,651 INFO resource_spec.py:212 -- Starting Ray with 3.81 GiB memory available for workers and up to 1.92 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>). 2021-02-15 14:01:44,913 INFO services.py:1093 -- View the Ray dashboard at localhost:8265 WARNING:root:Could not store dict entry model (type: <class 'str'>) WARNING:root:Could not store dict entry name (type: <class 'str'>) WARNING:root:Could not store dict entry description (type: <class 'str'>) WARNING:root:Could not store dict entry seed (type: <class 'NoneType'>) INFO:root:Starting 9 jobs. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00<00:00, 41.28it/s] INFO:root:Runs took 0.2351241111755371 s to submit. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:12<00:00, 1.35s/it] INFO:root:Runs and storage took 12.125471115112305 s to complete. After the exploration is done, we can load the results into a pandas Dataframe. By adding the argument arrays=True , we also tell mopet to load all simulated output (including arrays!) of the exploration into the Dataframe. ex . load_results ( arrays = True , as_dict = True ) INFO:root:exploration-82611.h5 opened for reading. INFO:root:Gettings runs of exploration ``exploration_2021_02_15_14H_01M_43S`` 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00<00:00, 172.57it/s] INFO:root:Creating new results DataFrame INFO:root:Aggregating all results ... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00<00:00, 228.06it/s] INFO:root:exploration-82611.h5 closed. Because we have used as_dict=True , the outputs of each run are also stored in the results dictionary. ex . results {0: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.16356391e-07, ..., 3.45083953e-02, 3.45104976e-02, 3.45125989e-02]]), 'rates_inh': array([[26.40960076, 26.72866115, 26.94340331, ..., 0.03753811, 0.03753869, 0.03753928]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}, 1: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.16356391e-07, ..., 2.59036677e-10, 2.59036677e-10, 2.59036677e-10]]), 'rates_inh': array([[26.40960076, 26.72866115, 26.99308004, ..., 5.42581999, 5.42581999, 5.42581999]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}, 2: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.16356391e-07, ..., 5.75384038e-13, 5.75384038e-13, 5.75384038e-13]]), 'rates_inh': array([[26.40960076, 26.72866115, 27.04275677, ..., 41.91810664, 41.91810664, 41.91810664]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}, 3: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.16754766e-07, ..., 3.10924479e+01, 3.10925428e+01, 3.10926376e+01]]), 'rates_inh': array([[26.40960076, 26.72866115, 26.94340331, ..., 17.85135676, 17.85138409, 17.8514114 ]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}, 4: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.16754766e-07, ..., 9.87365039e-02, 9.87387537e-02, 9.87410024e-02]]), 'rates_inh': array([[26.40960076, 26.72866115, 26.99308004, ..., 5.88861088, 5.88862208, 5.88863328]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}, 5: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.16754766e-07, ..., 5.75384038e-13, 5.75384038e-13, 5.75384038e-13]]), 'rates_inh': array([[26.40960076, 26.72866115, 27.04275677, ..., 41.91810664, 41.91810664, 41.91810664]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}, 6: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.17153140e-07, ..., 8.01355471e+01, 8.01356258e+01, 8.01357044e+01]]), 'rates_inh': array([[26.40960076, 26.72866115, 26.94340331, ..., 24.14426514, 24.14426982, 24.14427451]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}, 7: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.17153140e-07, ..., 6.66892386e+01, 6.66893269e+01, 6.66894151e+01]]), 'rates_inh': array([[26.40960076, 26.72866115, 26.99308004, ..., 69.74336334, 69.74337057, 69.74337779]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}, 8: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.17153140e-07, ..., 6.33525384e+01, 6.33526295e+01, 6.33527206e+01]]), 'rates_inh': array([[ 26.40960076, 26.72866115, 27.04275677, ..., 110.44781739, 110.44782441, 110.44783143]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}} Reducing the results As you can see, the results above are time series. For each simulation, we've got multiple arrays. We would like to visualize the results somehow. However, it can be quite challenging to plot many time series in a single figure and still understand what's happening. Therefore, to reduce the dimensionality of the data to a single scalar number per simulation, we will loop through the entire results Dataframe, grab the time series called rates_exc and simply compute its maximum after a transient time of t>500 time steps. We then store this number in the Dataframe and simply call the new column result . ex . df [ \"result\" ] = None for r in ex . df . index : t = ex . results [ r ][ 't' ] rates_exc = ex . results [ r ][ 'rates_exc' ] ex . df . loc [ r , \"result\" ] = np . max ( rates_exc [:, t > 500 ]) We can now inspect the updated dataframe using the attribute .df . ex . df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean 0 0 0 1 0 1.5 2 0 3 3 1.5 0 4 1.5 1.5 5 1.5 3 6 3 0 7 3 1.5 8 3 3 As you can see, the column result only has a single number for each run. Perfect for plotting! In order to plot this long-format Dataframe, we need to pivot it to create a new Dataframe pivoted which has the correct x and y coordinates for plotting the results value. pivoted = ex . df . pivot_table ( values = 'result' , index = 'mui_ext_mean' , columns = 'mue_ext_mean' , aggfunc = 'first' ) Let's have a look at the new Dataframe that we're about to plot. pivoted .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 ... 2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 2.9 3.0 mui_ext_mean 0.0 3.566714e-02 5.038073e+00 2.025389e+01 3.674348e+01 5.033596e+01 6.057443e+01 6.792469e+01 7.205380e+01 7.212920e+01 6.390489e+01 ... 5.204773e+01 5.536249e+01 5.862604e+01 61.839978 65.006270 68.125977 71.201859 74.234977 77.226649 80.178835 0.1 2.309179e-02 1.893093e-01 6.573055e+00 1.973052e+01 3.464734e+01 4.793192e+01 5.856197e+01 6.619381e+01 6.966394e+01 6.840042e+01 ... 4.956086e+01 5.297202e+01 5.632147e+01 59.612008 62.847173 66.029777 69.162763 72.248066 75.288125 78.285311 0.2 1.139727e-02 6.566545e-02 5.777425e-01 6.942009e+00 1.867513e+01 3.216752e+01 4.505146e+01 5.590772e+01 6.364450e+01 6.642131e+01 ... 4.733510e+01 5.084602e+01 5.428230e+01 57.648712 60.951266 64.194099 67.380941 70.515759 73.601047 76.639324 0.3 4.980980e-03 2.668306e-02 1.389261e-01 7.672331e-01 6.834751e+00 1.729525e+01 2.995169e+01 4.232013e+01 5.307061e+01 6.054178e+01 ... 4.534479e+01 4.895815e+01 5.248024e+01 55.920889 59.288067 62.587445 65.825477 69.005410 72.132165 75.208225 0.4 1.774000e-03 9.545725e-03 4.632592e-02 2.257016e-01 8.299970e-01 6.339486e+00 1.589181e+01 2.803041e+01 3.995661e+01 5.030109e+01 ... 4.356350e+01 4.727974e+01 5.088630e+01 54.398174 57.826662 61.179190 64.464000 67.686022 70.850201 73.960529 0.5 5.518867e-04 3.117537e-03 1.578428e-02 7.044940e-02 2.879694e-01 8.278262e-01 5.770501e+00 1.441105e+01 2.621844e+01 3.785076e+01 ... 4.196489e+01 4.578350e+01 4.947261e+01 53.052735 56.538380 59.940886 63.268404 66.529015 69.727161 72.868326 0.6 1.410664e-04 8.584281e-04 4.675732e-03 2.175138e-02 8.921891e-02 3.212336e-01 7.906348e-01 5.012672e+00 1.280725e+01 2.432060e+01 ... 4.052428e+01 4.444487e+01 4.821441e+01 51.859508 55.398690 58.846881 62.214551 65.509289 68.738692 71.907518 0.7 2.666909e-05 1.844340e-04 1.102892e-03 5.771147e-03 2.571231e-02 1.005409e-01 3.231891e-01 7.281859e-01 4.219999e+00 1.112888e+01 ... 3.922140e+01 4.324317e+01 4.708968e+01 50.795865 54.385822 57.876537 61.280031 64.606649 67.864156 71.057823 0.8 4.009508e-06 3.179702e-05 2.147151e-04 1.239125e-03 6.370432e-03 2.781132e-02 1.034079e-01 3.051518e-01 6.506604e-01 3.399014e+00 ... 3.803692e+01 4.215889e+01 4.607996e+01 49.844377 53.481517 57.011032 60.447884 63.803446 67.086149 70.302511 0.9 5.211367e-07 4.494865e-06 3.316653e-05 2.228548e-04 1.271082e-03 6.256895e-03 2.696717e-02 9.658404e-02 2.709520e-01 5.666516e-01 ... 3.695606e+01 4.117694e+01 4.516972e+01 48.989173 52.670173 56.235696 59.703132 63.085022 66.390763 69.627552 1.0 4.497921e-08 4.382856e-07 3.753760e-06 2.883101e-05 1.885120e-04 1.088116e-03 5.454615e-03 2.317611e-02 8.175859e-02 2.286241e-01 ... 3.596407e+01 4.028364e+01 4.434546e+01 48.216899 51.938838 55.537941 59.033403 62.439296 65.766181 69.021414 1.1 2.454856e-09 2.828892e-08 2.784138e-07 2.543065e-06 1.970298e-05 1.325695e-04 7.964396e-04 4.057528e-03 1.764448e-02 6.394733e-02 ... 3.505049e+01 3.946759e+01 4.359590e+01 47.516540 51.276760 54.907187 58.428464 61.856296 65.202224 68.474600 1.2 8.617726e-10 1.033598e-09 1.270822e-08 1.330508e-07 1.292857e-06 1.063115e-05 7.562577e-05 4.808429e-04 2.583567e-03 1.184341e-02 ... 3.420550e+01 3.871909e+01 4.291163e+01 46.878913 50.674992 54.334154 57.879714 61.327758 64.690995 67.979021 1.3 4.749090e-10 4.749090e-10 4.749090e-10 3.809268e-09 4.591911e-08 4.808315e-07 4.470947e-06 3.483011e-05 2.382303e-04 1.402141e-03 ... 3.342083e+01 3.803007e+01 4.228475e+01 46.296340 50.126070 53.811955 57.379414 60.846529 64.225870 67.527775 1.4 3.779369e-10 3.779369e-10 3.779369e-10 3.779369e-10 1.251640e-09 1.668310e-08 1.860033e-07 1.767367e-06 1.520766e-05 1.095455e-04 ... 3.268948e+01 3.739377e+01 4.170865e+01 45.762305 49.623654 53.334517 56.922280 60.406374 63.800751 67.115838 1.5 2.590367e-10 2.590367e-10 2.590367e-10 2.590367e-10 2.590367e-10 3.288077e-10 4.536740e-09 5.344076e-08 5.769909e-07 5.198401e-06 ... 3.200543e+01 3.680447e+01 4.117684e+01 45.270179 49.161303 52.895689 56.502829 60.003073 63.410852 66.737814 1.6 1.251886e-10 1.251886e-10 1.251886e-10 1.251886e-10 1.251886e-10 1.251886e-10 1.251886e-10 7.907271e-10 1.108750e-08 1.310678e-07 ... 1.772481e+00 3.625664e+01 4.068472e+01 44.816402 48.735648 52.491775 56.116466 59.631386 63.052248 66.390267 1.7 4.542324e-11 4.542324e-11 4.542324e-11 4.542324e-11 4.542324e-11 4.542324e-11 4.542324e-11 4.542324e-11 9.924273e-11 1.688537e-09 ... 8.180056e-01 1.792342e+00 4.022864e+01 44.396018 48.341665 52.118400 55.759885 59.288792 62.721043 66.069255 1.8 2.971878e-11 2.971878e-11 2.971878e-11 2.971878e-11 2.971878e-11 2.971878e-11 2.971878e-11 2.971878e-11 2.971878e-11 2.971878e-11 ... 3.593108e-01 7.246393e-01 3.980337e+01 44.005865 47.976716 51.772671 55.429416 58.971013 62.414508 65.772525 1.9 1.504514e-11 1.504514e-11 1.504514e-11 1.504514e-11 1.504514e-11 1.504514e-11 1.504514e-11 1.504514e-11 1.504514e-11 1.504514e-11 ... 1.058719e-01 2.819929e-01 6.712352e-01 43.642547 47.636960 51.451138 55.122567 58.676420 62.130072 65.496564 2.0 4.047458e-12 4.047458e-12 4.047458e-12 4.047458e-12 4.047458e-12 4.047458e-12 4.047458e-12 4.047458e-12 4.047458e-12 4.047458e-12 ... 1.755791e-02 7.188787e-02 2.278265e-01 0.710385 47.320899 51.152163 54.837136 58.401912 61.865056 65.240070 2.1 3.170746e-12 3.170746e-12 3.170746e-12 3.170746e-12 3.170746e-12 3.170746e-12 3.170746e-12 3.170746e-12 3.170746e-12 3.170746e-12 ... 2.157163e-03 1.212794e-02 5.480229e-02 0.203206 47.024924 50.872384 54.570262 58.145799 61.618114 65.000810 2.2 2.474273e-12 2.474273e-12 2.474273e-12 2.474273e-12 2.474273e-12 2.474273e-12 2.474273e-12 2.474273e-12 2.474273e-12 2.474273e-12 ... 2.521486e-04 1.721699e-03 1.013798e-02 0.049366 0.216226 50.610903 54.320970 57.906609 61.387091 64.776849 2.3 1.940476e-12 1.940476e-12 1.940476e-12 1.940476e-12 1.940476e-12 1.940476e-12 1.940476e-12 1.940476e-12 1.940476e-12 1.940476e-12 ... 3.130066e-05 2.555109e-04 1.817075e-03 0.010711 0.054714 0.316819 54.087366 57.682068 61.170426 64.567209 2.4 1.540749e-12 1.540749e-12 1.540749e-12 1.540749e-12 1.540749e-12 1.540749e-12 1.540749e-12 1.540749e-12 1.540749e-12 1.540749e-12 ... 4.385798e-06 4.346083e-05 3.511440e-04 0.002435 0.014367 0.077998 53.867577 57.471239 60.967217 64.370566 2.5 1.244689e-12 1.244689e-12 1.244689e-12 1.244689e-12 1.244689e-12 1.244689e-12 1.244689e-12 1.244689e-12 1.244689e-12 1.244689e-12 ... 7.471609e-07 8.428183e-06 7.756259e-05 0.000619 0.004133 0.023924 53.660989 57.273101 60.776234 64.185135 2.6 1.025698e-12 1.025698e-12 1.025698e-12 1.025698e-12 1.025698e-12 1.025698e-12 1.025698e-12 1.025698e-12 1.025698e-12 1.025698e-12 ... 1.537594e-07 1.855367e-06 2.024127e-05 0.000178 0.001317 0.008475 0.050404 57.086449 60.595775 64.010538 2.7 8.627628e-13 8.627628e-13 8.627628e-13 8.627628e-13 8.627628e-13 8.627628e-13 8.627628e-13 8.627628e-13 8.627628e-13 8.627628e-13 ... 3.749910e-08 5.039620e-07 5.941546e-06 0.000059 0.000472 0.003333 0.020206 56.909811 60.425557 63.845853 2.8 7.403169e-13 7.403169e-13 7.403169e-13 7.403169e-13 7.403169e-13 7.403169e-13 7.403169e-13 7.403169e-13 7.403169e-13 7.403169e-13 ... 1.059124e-08 1.534140e-07 2.023165e-06 0.000021 0.000190 0.001452 0.009229 56.742925 60.264750 63.690263 2.9 6.471729e-13 6.471729e-13 6.471729e-13 6.471729e-13 6.471729e-13 6.471729e-13 6.471729e-13 6.471729e-13 6.471729e-13 6.471729e-13 ... 3.370684e-09 5.643513e-08 7.581333e-07 0.000009 0.000085 0.000679 0.004705 56.585028 60.112586 63.542675 3.0 5.753840e-13 5.753840e-13 5.753840e-13 5.753840e-13 5.753840e-13 5.753840e-13 5.753840e-13 5.753840e-13 5.753840e-13 5.753840e-13 ... 1.282160e-09 2.152856e-08 3.257588e-07 0.000004 0.000041 0.000354 0.002523 56.435399 59.968116 63.402682 31 rows \u00d7 31 columns Perfect, that's exactly what we need. We have two indices, which are both equal to the paramters that we have explored before. The only entry of the Dataframe is the results value that we've put in before. Now, let's plot this Dataframe using matplotlib.imshow() . plt . imshow ( pivoted , \\ extent = [ min ( ex . df . mue_ext_mean ), max ( ex . df . mue_ext_mean ), min ( ex . df . mui_ext_mean ), max ( ex . df . mui_ext_mean )], origin = 'lower' ) plt . colorbar ( label = 'Maximum firing rate' ) plt . xlabel ( \"Input to E\" ) plt . ylabel ( \"Input to I\" ) Text(0, 0.5, 'Input to I')","title":"Neurolib example"},{"location":"examples/neurolib_example/#parameter-exploration-with-neurolib","text":"In this example, we will draw a bifurcation diagram of a neural mass model that we load using the brain simulation framework neurolib . Please visit the Github repo to learn more about this library or read the gentle introduction to neurolib to learn more about the neuroscience background of neural mass models and whole-brain simulations.","title":"Parameter exploration with neurolib"},{"location":"examples/neurolib_example/#what-we-will-do","text":"We will scan through a 2-dimensional parameter space and record all outputs of the model to a hdf file. We will then load the simulated results from the hdf file and condense the output to a single scalar so we can plot it. Let's get to it! We'll first start with some unnecessary but useful imports for logging and auto-reloading code. You can skip this block if you don't know what it does. # change into the root directory of the project import os if os . getcwd () . split ( \"/\" )[ - 1 ] == \"examples\" : os . chdir ( '..' ) % load_ext autoreload % autoreload 2 import logging logger = logging . getLogger () logger . setLevel ( logging . INFO ) We have to install matplotlib and neurolib for this example, which we can do using the shell command syntax of jupyter using !pip install matplotlib . # install matplotlib ! pip install matplotlib import matplotlib.pyplot as plt import numpy as np # a nice color map plt . rcParams [ 'image.cmap' ] = 'plasma' # install neurolib ! pip install neurolib from neurolib.models.aln import ALNModel import mopet We can now load the ALNModel model from neurolib . model = ALNModel () model . params . duration = 1 * 1000 INFO:root:aln: Model initialized. Like in other examples, we need to define an evalFunction that mopet can call. The parameters params that are passed to that function are the parameters of the model to run. We load the parameters to the model using a simple dictionary update old_dict.update(new_dict) . We then return the output of the model. def evalFunction ( params ): model . params . update ( params ) model . run () return model . outputs Now we define the parameter ranges to explore (the parameters here are called mue_ext_mean and mui_ext_mean which represent the background input to two neural populations). # NOTE: These values are low for testing! explore_params = { \"mue_ext_mean\" : np . linspace ( 0 , 3 , 3 ), \"mui_ext_mean\" : np . linspace ( 0 , 3 , 3 )} # For a real run, use these values: # explore_params = {\"mue_ext_mean\" : np.linspace(0, 3, 31), # \"mui_ext_mean\" : np.linspace(0, 3, 31)} # we need this random filename to avoid testing clashes hdf_filename = f \"exploration- { np . random . randint ( 99999 ) } .h5\" ex = mopet . Exploration ( evalFunction , explore_params , default_params = model . params , hdf_filename = hdf_filename ) Everything is ready and we can now simply run the exploration. ex . run () 2021-02-15 14:01:44,651 INFO resource_spec.py:212 -- Starting Ray with 3.81 GiB memory available for workers and up to 1.92 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>). 2021-02-15 14:01:44,913 INFO services.py:1093 -- View the Ray dashboard at localhost:8265 WARNING:root:Could not store dict entry model (type: <class 'str'>) WARNING:root:Could not store dict entry name (type: <class 'str'>) WARNING:root:Could not store dict entry description (type: <class 'str'>) WARNING:root:Could not store dict entry seed (type: <class 'NoneType'>) INFO:root:Starting 9 jobs. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00<00:00, 41.28it/s] INFO:root:Runs took 0.2351241111755371 s to submit. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:12<00:00, 1.35s/it] INFO:root:Runs and storage took 12.125471115112305 s to complete. After the exploration is done, we can load the results into a pandas Dataframe. By adding the argument arrays=True , we also tell mopet to load all simulated output (including arrays!) of the exploration into the Dataframe. ex . load_results ( arrays = True , as_dict = True ) INFO:root:exploration-82611.h5 opened for reading. INFO:root:Gettings runs of exploration ``exploration_2021_02_15_14H_01M_43S`` 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00<00:00, 172.57it/s] INFO:root:Creating new results DataFrame INFO:root:Aggregating all results ... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00<00:00, 228.06it/s] INFO:root:exploration-82611.h5 closed. Because we have used as_dict=True , the outputs of each run are also stored in the results dictionary. ex . results {0: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.16356391e-07, ..., 3.45083953e-02, 3.45104976e-02, 3.45125989e-02]]), 'rates_inh': array([[26.40960076, 26.72866115, 26.94340331, ..., 0.03753811, 0.03753869, 0.03753928]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}, 1: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.16356391e-07, ..., 2.59036677e-10, 2.59036677e-10, 2.59036677e-10]]), 'rates_inh': array([[26.40960076, 26.72866115, 26.99308004, ..., 5.42581999, 5.42581999, 5.42581999]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}, 2: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.16356391e-07, ..., 5.75384038e-13, 5.75384038e-13, 5.75384038e-13]]), 'rates_inh': array([[26.40960076, 26.72866115, 27.04275677, ..., 41.91810664, 41.91810664, 41.91810664]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}, 3: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.16754766e-07, ..., 3.10924479e+01, 3.10925428e+01, 3.10926376e+01]]), 'rates_inh': array([[26.40960076, 26.72866115, 26.94340331, ..., 17.85135676, 17.85138409, 17.8514114 ]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}, 4: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.16754766e-07, ..., 9.87365039e-02, 9.87387537e-02, 9.87410024e-02]]), 'rates_inh': array([[26.40960076, 26.72866115, 26.99308004, ..., 5.88861088, 5.88862208, 5.88863328]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}, 5: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.16754766e-07, ..., 5.75384038e-13, 5.75384038e-13, 5.75384038e-13]]), 'rates_inh': array([[26.40960076, 26.72866115, 27.04275677, ..., 41.91810664, 41.91810664, 41.91810664]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}, 6: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.17153140e-07, ..., 8.01355471e+01, 8.01356258e+01, 8.01357044e+01]]), 'rates_inh': array([[26.40960076, 26.72866115, 26.94340331, ..., 24.14426514, 24.14426982, 24.14427451]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}, 7: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.17153140e-07, ..., 6.66892386e+01, 6.66893269e+01, 6.66894151e+01]]), 'rates_inh': array([[26.40960076, 26.72866115, 26.99308004, ..., 69.74336334, 69.74337057, 69.74337779]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}, 8: {'IA': array([[159.05706529, 158.97753676, 158.89804799, ..., 1.07198599, 1.07145 , 1.07091428]]), 'rates_exc': array([[1.02403238e-07, 1.09923893e-07, 1.17153140e-07, ..., 6.33525384e+01, 6.33526295e+01, 6.33527206e+01]]), 'rates_inh': array([[ 26.40960076, 26.72866115, 27.04275677, ..., 110.44781739, 110.44782441, 110.44783143]]), 't': array([1.000e-01, 2.000e-01, 3.000e-01, ..., 9.998e+02, 9.999e+02, 1.000e+03])}}","title":"What we will do"},{"location":"examples/neurolib_example/#reducing-the-results","text":"As you can see, the results above are time series. For each simulation, we've got multiple arrays. We would like to visualize the results somehow. However, it can be quite challenging to plot many time series in a single figure and still understand what's happening. Therefore, to reduce the dimensionality of the data to a single scalar number per simulation, we will loop through the entire results Dataframe, grab the time series called rates_exc and simply compute its maximum after a transient time of t>500 time steps. We then store this number in the Dataframe and simply call the new column result . ex . df [ \"result\" ] = None for r in ex . df . index : t = ex . results [ r ][ 't' ] rates_exc = ex . results [ r ][ 'rates_exc' ] ex . df . loc [ r , \"result\" ] = np . max ( rates_exc [:, t > 500 ]) We can now inspect the updated dataframe using the attribute .df . ex . df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean mui_ext_mean 0 0 0 1 0 1.5 2 0 3 3 1.5 0 4 1.5 1.5 5 1.5 3 6 3 0 7 3 1.5 8 3 3 As you can see, the column result only has a single number for each run. Perfect for plotting! In order to plot this long-format Dataframe, we need to pivot it to create a new Dataframe pivoted which has the correct x and y coordinates for plotting the results value. pivoted = ex . df . pivot_table ( values = 'result' , index = 'mui_ext_mean' , columns = 'mue_ext_mean' , aggfunc = 'first' ) Let's have a look at the new Dataframe that we're about to plot. pivoted .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mue_ext_mean 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 ... 2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 2.9 3.0 mui_ext_mean 0.0 3.566714e-02 5.038073e+00 2.025389e+01 3.674348e+01 5.033596e+01 6.057443e+01 6.792469e+01 7.205380e+01 7.212920e+01 6.390489e+01 ... 5.204773e+01 5.536249e+01 5.862604e+01 61.839978 65.006270 68.125977 71.201859 74.234977 77.226649 80.178835 0.1 2.309179e-02 1.893093e-01 6.573055e+00 1.973052e+01 3.464734e+01 4.793192e+01 5.856197e+01 6.619381e+01 6.966394e+01 6.840042e+01 ... 4.956086e+01 5.297202e+01 5.632147e+01 59.612008 62.847173 66.029777 69.162763 72.248066 75.288125 78.285311 0.2 1.139727e-02 6.566545e-02 5.777425e-01 6.942009e+00 1.867513e+01 3.216752e+01 4.505146e+01 5.590772e+01 6.364450e+01 6.642131e+01 ... 4.733510e+01 5.084602e+01 5.428230e+01 57.648712 60.951266 64.194099 67.380941 70.515759 73.601047 76.639324 0.3 4.980980e-03 2.668306e-02 1.389261e-01 7.672331e-01 6.834751e+00 1.729525e+01 2.995169e+01 4.232013e+01 5.307061e+01 6.054178e+01 ... 4.534479e+01 4.895815e+01 5.248024e+01 55.920889 59.288067 62.587445 65.825477 69.005410 72.132165 75.208225 0.4 1.774000e-03 9.545725e-03 4.632592e-02 2.257016e-01 8.299970e-01 6.339486e+00 1.589181e+01 2.803041e+01 3.995661e+01 5.030109e+01 ... 4.356350e+01 4.727974e+01 5.088630e+01 54.398174 57.826662 61.179190 64.464000 67.686022 70.850201 73.960529 0.5 5.518867e-04 3.117537e-03 1.578428e-02 7.044940e-02 2.879694e-01 8.278262e-01 5.770501e+00 1.441105e+01 2.621844e+01 3.785076e+01 ... 4.196489e+01 4.578350e+01 4.947261e+01 53.052735 56.538380 59.940886 63.268404 66.529015 69.727161 72.868326 0.6 1.410664e-04 8.584281e-04 4.675732e-03 2.175138e-02 8.921891e-02 3.212336e-01 7.906348e-01 5.012672e+00 1.280725e+01 2.432060e+01 ... 4.052428e+01 4.444487e+01 4.821441e+01 51.859508 55.398690 58.846881 62.214551 65.509289 68.738692 71.907518 0.7 2.666909e-05 1.844340e-04 1.102892e-03 5.771147e-03 2.571231e-02 1.005409e-01 3.231891e-01 7.281859e-01 4.219999e+00 1.112888e+01 ... 3.922140e+01 4.324317e+01 4.708968e+01 50.795865 54.385822 57.876537 61.280031 64.606649 67.864156 71.057823 0.8 4.009508e-06 3.179702e-05 2.147151e-04 1.239125e-03 6.370432e-03 2.781132e-02 1.034079e-01 3.051518e-01 6.506604e-01 3.399014e+00 ... 3.803692e+01 4.215889e+01 4.607996e+01 49.844377 53.481517 57.011032 60.447884 63.803446 67.086149 70.302511 0.9 5.211367e-07 4.494865e-06 3.316653e-05 2.228548e-04 1.271082e-03 6.256895e-03 2.696717e-02 9.658404e-02 2.709520e-01 5.666516e-01 ... 3.695606e+01 4.117694e+01 4.516972e+01 48.989173 52.670173 56.235696 59.703132 63.085022 66.390763 69.627552 1.0 4.497921e-08 4.382856e-07 3.753760e-06 2.883101e-05 1.885120e-04 1.088116e-03 5.454615e-03 2.317611e-02 8.175859e-02 2.286241e-01 ... 3.596407e+01 4.028364e+01 4.434546e+01 48.216899 51.938838 55.537941 59.033403 62.439296 65.766181 69.021414 1.1 2.454856e-09 2.828892e-08 2.784138e-07 2.543065e-06 1.970298e-05 1.325695e-04 7.964396e-04 4.057528e-03 1.764448e-02 6.394733e-02 ... 3.505049e+01 3.946759e+01 4.359590e+01 47.516540 51.276760 54.907187 58.428464 61.856296 65.202224 68.474600 1.2 8.617726e-10 1.033598e-09 1.270822e-08 1.330508e-07 1.292857e-06 1.063115e-05 7.562577e-05 4.808429e-04 2.583567e-03 1.184341e-02 ... 3.420550e+01 3.871909e+01 4.291163e+01 46.878913 50.674992 54.334154 57.879714 61.327758 64.690995 67.979021 1.3 4.749090e-10 4.749090e-10 4.749090e-10 3.809268e-09 4.591911e-08 4.808315e-07 4.470947e-06 3.483011e-05 2.382303e-04 1.402141e-03 ... 3.342083e+01 3.803007e+01 4.228475e+01 46.296340 50.126070 53.811955 57.379414 60.846529 64.225870 67.527775 1.4 3.779369e-10 3.779369e-10 3.779369e-10 3.779369e-10 1.251640e-09 1.668310e-08 1.860033e-07 1.767367e-06 1.520766e-05 1.095455e-04 ... 3.268948e+01 3.739377e+01 4.170865e+01 45.762305 49.623654 53.334517 56.922280 60.406374 63.800751 67.115838 1.5 2.590367e-10 2.590367e-10 2.590367e-10 2.590367e-10 2.590367e-10 3.288077e-10 4.536740e-09 5.344076e-08 5.769909e-07 5.198401e-06 ... 3.200543e+01 3.680447e+01 4.117684e+01 45.270179 49.161303 52.895689 56.502829 60.003073 63.410852 66.737814 1.6 1.251886e-10 1.251886e-10 1.251886e-10 1.251886e-10 1.251886e-10 1.251886e-10 1.251886e-10 7.907271e-10 1.108750e-08 1.310678e-07 ... 1.772481e+00 3.625664e+01 4.068472e+01 44.816402 48.735648 52.491775 56.116466 59.631386 63.052248 66.390267 1.7 4.542324e-11 4.542324e-11 4.542324e-11 4.542324e-11 4.542324e-11 4.542324e-11 4.542324e-11 4.542324e-11 9.924273e-11 1.688537e-09 ... 8.180056e-01 1.792342e+00 4.022864e+01 44.396018 48.341665 52.118400 55.759885 59.288792 62.721043 66.069255 1.8 2.971878e-11 2.971878e-11 2.971878e-11 2.971878e-11 2.971878e-11 2.971878e-11 2.971878e-11 2.971878e-11 2.971878e-11 2.971878e-11 ... 3.593108e-01 7.246393e-01 3.980337e+01 44.005865 47.976716 51.772671 55.429416 58.971013 62.414508 65.772525 1.9 1.504514e-11 1.504514e-11 1.504514e-11 1.504514e-11 1.504514e-11 1.504514e-11 1.504514e-11 1.504514e-11 1.504514e-11 1.504514e-11 ... 1.058719e-01 2.819929e-01 6.712352e-01 43.642547 47.636960 51.451138 55.122567 58.676420 62.130072 65.496564 2.0 4.047458e-12 4.047458e-12 4.047458e-12 4.047458e-12 4.047458e-12 4.047458e-12 4.047458e-12 4.047458e-12 4.047458e-12 4.047458e-12 ... 1.755791e-02 7.188787e-02 2.278265e-01 0.710385 47.320899 51.152163 54.837136 58.401912 61.865056 65.240070 2.1 3.170746e-12 3.170746e-12 3.170746e-12 3.170746e-12 3.170746e-12 3.170746e-12 3.170746e-12 3.170746e-12 3.170746e-12 3.170746e-12 ... 2.157163e-03 1.212794e-02 5.480229e-02 0.203206 47.024924 50.872384 54.570262 58.145799 61.618114 65.000810 2.2 2.474273e-12 2.474273e-12 2.474273e-12 2.474273e-12 2.474273e-12 2.474273e-12 2.474273e-12 2.474273e-12 2.474273e-12 2.474273e-12 ... 2.521486e-04 1.721699e-03 1.013798e-02 0.049366 0.216226 50.610903 54.320970 57.906609 61.387091 64.776849 2.3 1.940476e-12 1.940476e-12 1.940476e-12 1.940476e-12 1.940476e-12 1.940476e-12 1.940476e-12 1.940476e-12 1.940476e-12 1.940476e-12 ... 3.130066e-05 2.555109e-04 1.817075e-03 0.010711 0.054714 0.316819 54.087366 57.682068 61.170426 64.567209 2.4 1.540749e-12 1.540749e-12 1.540749e-12 1.540749e-12 1.540749e-12 1.540749e-12 1.540749e-12 1.540749e-12 1.540749e-12 1.540749e-12 ... 4.385798e-06 4.346083e-05 3.511440e-04 0.002435 0.014367 0.077998 53.867577 57.471239 60.967217 64.370566 2.5 1.244689e-12 1.244689e-12 1.244689e-12 1.244689e-12 1.244689e-12 1.244689e-12 1.244689e-12 1.244689e-12 1.244689e-12 1.244689e-12 ... 7.471609e-07 8.428183e-06 7.756259e-05 0.000619 0.004133 0.023924 53.660989 57.273101 60.776234 64.185135 2.6 1.025698e-12 1.025698e-12 1.025698e-12 1.025698e-12 1.025698e-12 1.025698e-12 1.025698e-12 1.025698e-12 1.025698e-12 1.025698e-12 ... 1.537594e-07 1.855367e-06 2.024127e-05 0.000178 0.001317 0.008475 0.050404 57.086449 60.595775 64.010538 2.7 8.627628e-13 8.627628e-13 8.627628e-13 8.627628e-13 8.627628e-13 8.627628e-13 8.627628e-13 8.627628e-13 8.627628e-13 8.627628e-13 ... 3.749910e-08 5.039620e-07 5.941546e-06 0.000059 0.000472 0.003333 0.020206 56.909811 60.425557 63.845853 2.8 7.403169e-13 7.403169e-13 7.403169e-13 7.403169e-13 7.403169e-13 7.403169e-13 7.403169e-13 7.403169e-13 7.403169e-13 7.403169e-13 ... 1.059124e-08 1.534140e-07 2.023165e-06 0.000021 0.000190 0.001452 0.009229 56.742925 60.264750 63.690263 2.9 6.471729e-13 6.471729e-13 6.471729e-13 6.471729e-13 6.471729e-13 6.471729e-13 6.471729e-13 6.471729e-13 6.471729e-13 6.471729e-13 ... 3.370684e-09 5.643513e-08 7.581333e-07 0.000009 0.000085 0.000679 0.004705 56.585028 60.112586 63.542675 3.0 5.753840e-13 5.753840e-13 5.753840e-13 5.753840e-13 5.753840e-13 5.753840e-13 5.753840e-13 5.753840e-13 5.753840e-13 5.753840e-13 ... 1.282160e-09 2.152856e-08 3.257588e-07 0.000004 0.000041 0.000354 0.002523 56.435399 59.968116 63.402682 31 rows \u00d7 31 columns Perfect, that's exactly what we need. We have two indices, which are both equal to the paramters that we have explored before. The only entry of the Dataframe is the results value that we've put in before. Now, let's plot this Dataframe using matplotlib.imshow() . plt . imshow ( pivoted , \\ extent = [ min ( ex . df . mue_ext_mean ), max ( ex . df . mue_ext_mean ), min ( ex . df . mui_ext_mean ), max ( ex . df . mui_ext_mean )], origin = 'lower' ) plt . colorbar ( label = 'Maximum firing rate' ) plt . xlabel ( \"Input to E\" ) plt . ylabel ( \"Input to I\" ) Text(0, 0.5, 'Input to I')","title":"Reducing the results"}]}